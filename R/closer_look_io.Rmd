---
title: "closer look at inputs and outputs"
output: html_notebook
---

```{r packages}
#load packages
library(tidyverse)
library(keras)
library(rjson)
library(repurrrsive)
library(listviewer)
library(reticulate)
library(magick) 

library(here)
```

```{r load}
#image directory
img_dir <- file.path(here(), "example_photos") #"source_photos"

#descriptor - some descriptor to organise adn separate runs using this code from others
descriptor <- "ssd"

#import prepped data - using import script
# source("R/data_prep.R")

#import additional functions
source(file.path(here(), "R/sample_image.R"))

#or import prepped data from folder
boxinfo <- read_csv(file.path(here(), "data/boxinfo_forskeydan.csv"))  #read_csv("data/boxinfo.csv"))
imageinfo <- read_csv(file.path(here(), "data/imageinfo_forskeydan.csv"))  #read_csv("data/imageinfo.csv"))
catinfo <- read_csv(file.path(here(), "data/catinfo_forskeydan.csv"))  #read_csv("data/catinfo.csv"))
n_classes <- nrow(catinfo)

```

```{r}
# Scaling---

# scale all bounding box coordinates according to the actual image size weâ€™ll
# use when we pass it to our network.

target_height <- 224
target_width <- 224

imageinfo <- imageinfo %>% 
  mutate(
    x_left_scaled = (x_left / image_width * target_width) %>% round(),
    x_right_scaled = (x_right / image_width * target_width) %>% round(),
    y_top_scaled = (y_top / image_height * target_height) %>% round(),
    y_bottom_scaled = (y_bottom / image_height * target_height) %>% round(),
    bbox_width_scaled =  (bbox_width / image_width * target_width) %>% round(),
    bbox_height_scaled = (bbox_height / image_height * target_height) %>% round()
  )

# Aggregate information ----
#aggregate all information on a single image into a single row.

imageinfo4ssd <- imageinfo %>%
  select(category_id, file_name, name,
         x_left, y_top, x_right, y_bottom,
         ends_with("scaled"))

imageinfo4ssd <- imageinfo4ssd %>%
  group_by(file_name) %>%
  summarise(
    categories = toString(category_id),
    name = toString(name),
    xl = toString(x_left_scaled),
    yt = toString(y_top_scaled),
    xr = toString(x_right_scaled),
    yb = toString(y_bottom_scaled),
    xl_orig = toString(x_left),
    yt_orig = toString(y_top),
    xr_orig = toString(x_right),
    yb_orig = toString(y_bottom),
    cnt = n()
  )

imageinfo4ssd <- imageinfo4ssd %>% filter(name != "NA") 

#write_rds(imageinfo4ssd, path = "data/imageinfo4ssd.RData")
```

```{r}
#subset image info to use only images in img_dir
img_seld <- list.files(img_dir)
```

```{r}
#create a parameter for the image info
imageinfo_input <- imageinfo4ssd %>% filter(file_name %in% img_seld)
```


```{r}
#show an example image: 
#sample_image(img_data = imageinfo_input, img_name = "random")
sample_image(img_data = imageinfo_input, img_name = "IMG_5277.JPG", img_dir = img_dir)
```

```{r}
# define anchors

cells_per_row <- 4
gridsize <- 1/cells_per_row
anchor_offset <- 1 / (cells_per_row * 2) 

anchor_xs <- seq(anchor_offset, 1 - anchor_offset, length.out = 4) %>%
  rep(each = cells_per_row)
anchor_ys <- seq(anchor_offset, 1 - anchor_offset, length.out = 4) %>%
  rep(cells_per_row)

anchor_centers <- cbind(anchor_xs, anchor_ys)
anchor_height_width <- matrix(1 / cells_per_row, nrow = 16, ncol = 2)

#defines anchor centres, height and width
anchors <- cbind(anchor_centers, anchor_height_width)

#defines grid cell corners
# cells are indicated by (xl, yt, xr, yb)
# successive rows first go down in the image, then to the right
hw2corners <- function(centers, height_width) {
  cbind(centers - height_width / 2, centers + height_width / 2) %>% unname()
}
anchor_corners <- hw2corners(anchor_centers, anchor_height_width)
```

```{r}
#visualise anchor corners, anchor centres and grid cell ids
anchor_corners_df <- data.frame(anchor_corners); names(anchor_corners_df) <- c("xl", "yt", "xr", "yb")
anchor_data <- data.frame(id = 1:nrow(anchor_corners_df), x = anchor_xs, y = anchor_ys, anchor_corners_df)
ggplot(anchor_data, aes(x, y)) +
  geom_rect(aes(xmin = xl, xmax = xr, ymin = yb, ymax = yt), colour = "blue", fill = "none") +
  geom_point() +
  geom_text(aes(label = id), colour = "red", nudge_x = 0.065, nudge_y = 0.065) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  theme(aspect.ratio = 1)
```


```{r}
# overlaps shape is: number of ground truth objects * number of grid cells
map_to_ground_truth <- function(overlaps) {
  
  # for each ground truth object, find maximally overlapping cell (crit. 1)
  # measure of overlap, shape: number of ground truth objects
  prior_overlap <- apply(overlaps, 1, max)
  # which cell is this, for each object
  prior_idx <- apply(overlaps, 1, which.max)
  
  # for each grid cell, what object does it overlap with most (crit. 2)
  # measure of overlap, shape: number of grid cells
  gt_overlap <-  apply(overlaps, 2, max)
  # which object is this, for each cell
  gt_idx <- apply(overlaps, 2, which.max)
  
  # set all definitely overlapping cells to respective object (crit. 1)
  gt_overlap[prior_idx] <- 1.99
  
  # now still set all others to best match by crit. 2
  # actually it's other way round, we start from (2) and overwrite with (1)
  for (i in 1:length(prior_idx)) {
    # iterate over all cells "absolutely assigned"
    p <- prior_idx[i] # get respective grid cell
    gt_idx[p] <- i # assign this cell the object number
  }
  
  # return: for each grid cell, object it overlaps with most + measure of overlap
  list(gt_overlap, gt_idx)
  
}
```

```{r}
# compute IOU
jaccard <- function(bbox, anchor_corners) {
  bbox <- k_constant(bbox)
  anchor_corners <- k_constant(anchor_corners)
  intersection <- intersect(bbox, anchor_corners)
  union <-
    k_expand_dims(box_area(bbox), axis = 2)  + k_expand_dims(box_area(anchor_corners), axis = 1) - intersection
  res <- intersection / union
  res %>% k_eval()
}

# compute intersection for IOU
intersect <- function(box1, box2) {
  box1_a <- box1[, 3:4] %>% k_expand_dims(axis = 2)
  box2_a <- box2[, 3:4] %>% k_expand_dims(axis = 1)
  max_xy <- k_minimum(box1_a, box2_a)
  
  box1_b <- box1[, 1:2] %>% k_expand_dims(axis = 2)
  box2_b <- box2[, 1:2] %>% k_expand_dims(axis = 1)
  min_xy <- k_maximum(box1_b, box2_b)
  
  intersection <- k_clip(max_xy - min_xy, min = 0, max = Inf)
  intersection[, , 1] * intersection[, , 2]
  
}

box_area <- function(box) {
  (box[, 3] - box[, 1]) * (box[, 4] - box[, 2]) 
}

```

###Breaking down the data generator
```{r}
#data generator ----
batch_size <- 16
image_size <- target_width # same as height
threshold <- 0.4
class_background <- 28  #n_classes + 1 - category assigned to background . 

  #fix for OSError: image file is truncated
PIL <- reticulate::import("PIL")
PIL$ImageFile$LOAD_TRUNCATED_IMAGES <- TRUE
```

#### image preprocessing
```{r}
#the image generator basically grabs and image and shoves all the pixels into an array.  Then does some preprocessing for xception
#image generator
load_and_preprocess_image <- function(image_name, target_height, target_width, img_dir = "source_photos") {
  img_array <- image_load(
    file.path(img_dir, image_name),
    target_size = c(target_height, target_width)
  ) %>%
    image_to_array() %>%
    xception_preprocess_input() 
  dim(img_array) <- c(1, dim(img_array))
  img_array
}
```


```{r}
#data generator ctd
# ssd_generator <-
#   function(
data <- imageinfo_input
target_height  <-  target_height
target_width <-  target_width
shuffle <- FALSE
batch_size <- batch_size
```



```{r}
#This iterates through the batches.  We're only going to do one batch. With no shuffling
i <- 1
 #   function() {
      if (shuffle) {
        indices <- sample(1:nrow(data), size = batch_size)
      } else {
        if (i + batch_size >= nrow(data))
          i <<- 1
        indices <- c(i:min(i + batch_size - 1, nrow(data)))
        i <<- i + length(indices)
      }
#we've defined the indices, 1 to 16, so the first 16 images will be selected 
```


```{r}
# set up empty arrays
      x <- array(0, dim = c(length(indices), target_height, target_width, 3))
        #this is to receive the image array 
      y1 <- array(0, dim = c(length(indices), 16))
        #this is to receive the classes for each bounding box as a single vector for each image
      y2 <- array(0, dim = c(length(indices), 16, 4))
        #this is to receive the bounding box coordinates as four vectors for each image
```

####Process the images one by one
```{r}
#we're going to step into the function and look at only one image
#      k <- 1 #counter for images within batch
j <- 1 #      for (j in 1:length(indices)) {
img_name <- data[[indices[j], "file_name"]]
#and just to see what we're dealing with, here's the image: 
sample_image(img_data = data, img_name = img_name, img_dir = img_dir)
```

```{r}
#read the image into array x
        x[j, , , ] <- load_and_preprocess_image(data[[indices[j], "file_name"]], 
                                                img_dir = img_dir,
                                                target_height, target_width)
```

```{r}
#read the categories and bounding boxes from the image_data
        class_string <- data[indices[j], ]$categories
        xl_string <- data[indices[j], ]$xl
        yt_string <- data[indices[j], ]$yt
        xr_string <- data[indices[j], ]$xr
        yb_string <- data[indices[j], ]$yb
        
        #chop it all up and also rescale the coordinates
        classes <-  str_split(class_string, pattern = ", ")[[1]]
        xl <- str_split(xl_string, pattern = ", ")[[1]] %>% as.double() %>% `/`(image_size)
        yt <- str_split(yt_string, pattern = ", ")[[1]] %>% as.double() %>% `/`(image_size)
        xr <- str_split(xr_string, pattern = ", ")[[1]] %>% as.double() %>% `/`(image_size)
        yb <- str_split(yb_string, pattern = ", ")[[1]] %>% as.double() %>% `/`(image_size)
```

```{r}
#Now we're going to calculate overlaps and assign anchor cells to objects

      # rows are objects, columns are coordinates (xl, yt, xr, yb)
      # anchor_corners are 16 rows with corresponding coordinates
        bbox <- cbind(xl, yt, xr, yb) #this contains all the boundign boxes for tagged objects
      # calculate overlaps
        overlaps <- jaccard(bbox, anchor_corners)
#        
#lets have a look
head(bbox)
```

```{r}
# #lets visualise
# img_gg <- image_read(path = file.path(here(), "data/temp_img.png")) 
# 
# anch_gg <-image_graph(width = image_info(img_gg)[["width"]], height = image_info(img_gg)[["height"]])
#  ggplot(anchor_data, aes(x, y)) +
#   geom_rect(aes(xmin = xl, xmax = xr, ymin = yb, ymax = yt), colour = "blue", fill = "none") +
#   geom_point() +
#   geom_text(aes(label = id), colour = "red", nudge_x = 0.065, nudge_y = 0.065) +
#   coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
#   theme(aspect.ratio = 1) + theme_minimal()
# dev.off()
# image_composite(img_gg, anch_gg, operator = "overlay")
```


```{r}
overlaps
```
So here we can see the jaccard index of each pair of cell and ground truth box 
```{r echo=T}        
# 
        c(gt_overlap, gt_idx) %<-% map_to_ground_truth(overlaps)
        gt_class <- classes[gt_idx]
        
        pos <- gt_overlap > threshold
        gt_class[gt_overlap < threshold] <- 28
        
        # columns correspond to objects
        boxes <- rbind(xl, yt, xr, yb)
        # columns correspond to object boxes according to gt_idx
        gt_bbox <- boxes[, gt_idx]
        # set those with non-sufficient overlap to 0
        gt_bbox[, !pos] <- 0
        gt_bbox <- gt_bbox %>% t()
        
        y1[j, ] <- as.integer(gt_class) - 1
        y2[j, , ] <- gt_bbox

gt_class; as.integer(gt_class) -1                
```




```{r}
      x <- x %>% imagenet_preprocess_input()
      y1 <- y1 %>% to_categorical(num_classes = class_background)

      list(x, list(y1, y2))
   # }
  #}
```



```{r}
#lets have a look at the inputs - there are 16 images per batch but we've only processed one image so far, so we're just going to look at the first element in each array:
paste("x"); head(x[1,,,])  #this is the image array containing the pixel values and the three colour channels.  I'll abbreviate it
paste("y1");y1[1,,] #this is the classes array, for the 16 selected bounding boxes and the 28 categories.  We can see that it's selected 5 boxes for cat 4, 2 for cat 14, 2 for cat 15, and 7 for cat 28.  cat 10 is in the original but not represented in the processed data.  
paste("y2");y2[1,,] #this is the bounding box array.  4 coordinates for each bounding box 

```


```{r}
#lets have a look
df_box_sels <- data.frame(y2[1,,]); names(df_box_sels) <- c("xl", "yt", "xr", "yb")
pad <- 0.1 #proportion to pad box by
img <- image_read(file.path(img_dir, img_name))
df_box <- df_box_sels
names(df_box) <- c("xl", "yt", "xr", "yb")

#rescale
x_left <- df_box$xl * image_info(img)[[1,"width"]]
x_right <- df_box$xr * image_info(img)[[1,"width"]]
y_top <- df_box$yt * image_info(img)[[1,"height"]]
y_bottom <- df_box$yb * image_info(img)[[1,"height"]]


img <- image_draw(img)
# textHeight <- graphics::strheight(label, cex = cex)
# textWidth <- graphics::strwidth(label, cex = cex)
for (i in 1:nrow(df_box)) {
  rect(xleft = x_left[i], ybottom = y_bottom[i],
       xright = x_right[i], ytop = y_top[i],
       border = "white", lwd = 5)
  # rect(xleft = as.integer(x_right[i]) - (textWidth[i] * (1 + pad)), 
  #      ybottom = as.integer(y_top[i]) - (textHeight[i] * (1 + pad)), 
  #      xright = as.integer(x_right[i]) + (textWidth[i] * pad), 
  #      ytop = as.integer(y_top[i]) + (textHeight[i] * pad),
  #      col = "white", border = NA) 
  # text(x = as.integer(x_right[i]), y = as.integer(y_top[i]), labels = label[i], 
  #      cex = cex, 
  #      adj = c(1,1), 
  #      col = "black", vfont = c("sans serif", "bold"))
}

dev.off()
print(img)
```


```{r}
#training generator ----
  #This generates the inputs to the model, in batches.  
train_gen <- ssd_generator(
  imageinfo_input,
  target_height = target_height,
  target_width = target_width,
  #shuffle = FALSE,
  shuffle = TRUE,
  batch_size = batch_size
)
```

```{r}
#test the generator
batch <- train_gen() #generate one batch
c(x, c(y1, y2)) %<-% batch #extract list elements
dim(y1) #classes
dim(y2) #bounding boxes
dim(x) #image tensor

```


